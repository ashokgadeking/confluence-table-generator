||No.||Subprops of AWS_DMS_Endpoint DocDbSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|DocsToInvestigate| Indicates the number of documents to preview to determine the document organization. Use this setting when NestingLevel is set to "one". |Integer| |Yes| | |
|2|ExtractDocId| Specifies the document ID. Use this setting when NestingLevel is set to "none". |Boolean| |Yes|Yes| |
|3|SecretsManagerSecretId|The full ARN, partial ARN, or display name of the SecretsManagerSecret that contains the DocumentDB endpoint connection details.|String| |Yes|Yes| |
|4|SecretsManagerAccessRoleArn|The full Amazon Resource Name (ARN) of the IAM role that specifies AWS DMS as the trusted entity and grants the required permissions to access the value in SecretsManagerSecret. The role must allow the iam:PassRole action. SecretsManagerSecret has the value of the AWS Secrets Manager secret that allows access to the DocumentDB endpoint.|String| |Yes|Yes| |
|5|NestingLevel| Specifies either document or table mode. |String| |Yes| | |
||No.||Subprops of AWS_DMS_Endpoint DynamoDbSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|ServiceAccessRoleArn| The Amazon Resource Name (ARN) used by the service to access the IAM role. The role must allow the iam:PassRole action.|String| |Yes|Yes| |
||No.||Subprops of AWS_DMS_Endpoint ElasticsearchSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|EndpointUri|The endpoint for the OpenSearch cluster. AWS DMS uses HTTPS if a transport  protocol (either HTTP or HTTPS) isn't specified.|String| |No| | |
|2|FullLoadErrorPercentage|The maximum percentage of records that can fail to be written before a full load operation stops.|Integer| |No| | |
|3|ErrorRetryDuration|The maximum number of seconds for which DMS retries failed API requests to the OpenSearch cluster.|Integer| |Yes| | |
|4|ServiceAccessRoleArn|The Amazon Resource Name (ARN) used by the service to access the IAM role. The role must allow the iam:PassRole action.|String| |Yes|Yes| |
||No.||Subprops of AWS_DMS_Endpoint GcpMySQLSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|AfterConnectScript|Specifies a script to run immediately after AWS DMS connects to the endpoint.  The migration task continues running regardless if the SQL statement succeeds or fails.|String| |Yes| | |
|2|Port|The port used by the endpoint database.|Integer| |Yes| | |
|3|DatabaseName|Database name for the endpoint. For a MySQL source or target endpoint, don't explicitly specify  the database using the DatabaseName request parameter on either the CreateEndpoint or ModifyEndpoint API call. Specifying DatabaseName when you create or modify a  MySQL endpoint replicates all the task tables to this single database. For MySQL endpoints, you specify  the database only when you specify the schema in the table-mapping rules of the AWS DMS task. |String| |Yes| | |
|4|CleanSourceMetadataOnMismatch|Adjusts the behavior of AWS DMS when migrating from an SQL Server source database  that is hosted as part of an Always On availability group cluster. If you need AWS DMS to poll all the nodes in the Always On cluster for transaction backups, set this attribute to false. |Boolean| |Yes| | |
|5|ServerTimezone|Specifies the time zone for the source MySQL database. Don't enclose time zones in single quotation marks.|String| |Yes| | |
|6|EventsPollInterval|Specifies how often to check the binary log for new changes/events when the database is idle. The default is five seconds.|Integer| |Yes| | |
|7|ParallelLoadThreads|Improves performance when loading data into the MySQL-compatible target database. Specifies how many  threads to use to load the data into the MySQL-compatible target database. Setting a large number of  threads can have an adverse effect on database performance, because a separate connection is required  for each thread. The default is one.|Integer| |Yes| | |
|8|Username|Endpoint connection user name.|String| |Yes| | |
|9|MaxFileSize|Specifies the maximum size (in KB) of any .csv file used to transfer data to a MySQL-compatible database.|Integer| |Yes| | |
|10|ServerName|The MySQL host name.|String| |Yes| | |
|11|SecretsManagerSecretId|The full ARN, partial ARN, or display name of the SecretsManagerSecret that contains the MySQL endpoint connection details. |String| |Yes|Yes| |
|12|SecretsManagerAccessRoleArn|The full Amazon Resource Name (ARN) of the IAM role that specifies AWS DMS as the trusted entity and grants the required permissions to access the value in SecretsManagerSecret. The role must allow the iam:PassRole action. SecretsManagerSecret has the value of the AWS Secrets Manager secret that allows access to the MySQL endpoint.|String| |Yes|Yes| |
|13|Password|Endpoint connection password.|String| |Yes|Yes| |
||No.||Subprops of AWS_DMS_Endpoint IbmDb2Settings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|LoadTimeout|The amount of time (in milliseconds) before AWS DMS times out operations performed by DMS on the Db2 target. The default value is 1200 (20 minutes).|Integer| |Yes| | |
|2|SetDataCaptureChanges|Enables ongoing replication (CDC) as a BOOLEAN value. The default is true.|Boolean| |No| | |
|3|MaxFileSize|Specifies the maximum size (in KB) of .csv files used to transfer data to Db2 LUW.|Integer| |Yes| | |
|4|KeepCsvFiles|If true, AWS DMS saves any .csv files to the Db2 LUW target that were used to replicate data. DMS uses these  files for analysis and troubleshooting.|Boolean| |No| | |
|5|CurrentLsn|For ongoing replication (CDC), use CurrentLSN to specify a log sequence number (LSN) where you want the replication to start.|String| |No| | |
|6|MaxKBytesPerRead|Maximum number of bytes per read, as a NUMBER value. The default is 64 KB.|Integer| |No| | |
|7|SecretsManagerSecretId|The full ARN, partial ARN, or display name of the SecretsManagerSecret that contains the IBMDB2 endpoint connection details.|String| |Yes|Yes| |
|8|WriteBufferSize|The size (in KB) of the in-memory file write buffer used when generating .csv files on the local disk on the DMS replication instance. The default value is 1024 (1 MB).|Integer| |Yes| | |
|9|SecretsManagerAccessRoleArn|The full Amazon Resource Name (ARN) of the IAM role that specifies AWS DMS as the trusted entity and grants the required permissions to access the value in SecretsManagerSecret. The role must allow the iam:PassRole action. SecretsManagerSecret has the value ofthe AWS Secrets Manager secret that allows access to the Db2 LUW endpoint.|String| |Yes|Yes| |
||No.||Subprops of AWS_DMS_Endpoint KafkaSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|Broker|A comma-separated list of one or more broker locations in your Kafka cluster that host your Kafka instance. Specify each broker location in the form broker-hostname-or-ip:port. For example, "ec2-12-345-678-901.compute-1.amazonaws.com:2345". For more information and examples of specifying a list of broker locations, see  Using Apache Kafka as a target for AWS Database Migration Service in the  AWS Database Migration Service User Guide.|String| |No| | |
|2|SaslPassword|The secure password that you created when you first set up your Amazon MSK cluster to validate a client identity and  make an encrypted connection between server and client using SASL-SSL authentication. |String| |No|Yes| |
|3|MessageFormat|The output format for the records created on the endpoint. The message format is JSON (default) or JSON_UNFORMATTED (a single line with no tab).|String| |Yes| | |
|4|SslClientCertificateArn|The Amazon Resource Name (ARN) of the client certificate used to securely connect to a Kafka target endpoint.|String| |No|Yes| |
|5|IncludeTransactionDetails|Provides detailed transaction information from the source database. This information includes a commit timestamp, a log position, and values for transaction_id, previous transaction_id, and transaction_record_id (the record offset within a transaction). The default is false.|Boolean| |Yes| | |
|6|SecurityProtocol|Set secure connection to a Kafka target endpoint using Transport Layer Security (TLS). Options include  ssl-encryption, ssl-authentication, and sasl-ssl.  sasl-ssl requires SaslUsername and SaslPassword.|String| |No| | |
|7|IncludeTableAlterOperations|Includes any data definition language (DDL) operations that change the table in the control data, such as rename-table, drop-table, add-column, drop-column, and rename-column. The default is false.|Boolean| |Yes| | |
|8|SslCaCertificateArn| The Amazon Resource Name (ARN) for the private certificate authority (CA) cert that AWS DMS uses  to securely connect to your Kafka target endpoint.|String| |Yes|Yes| |
|9|IncludeControlDetails|Shows detailed control information for table definition, column definition, and table and column changes in the Kafka message output. The default is false.|Boolean| |Yes| | |
|10|IncludePartitionValue|Shows the partition value within the Kafka message output unless the partition type is schema-table-type. The default is false.|Boolean| |Yes| | |
|11|NoHexPrefix|Set this optional parameter to true to avoid adding a '0x' prefix to raw data in hexadecimal format. For example, by default, AWS DMS adds a '0x' prefix to the LOB column type in hexadecimal format moving from an Oracle source to a Kafka target. Use the NoHexPrefix endpoint setting to enable migration of RAW data type columns without adding the '0x' prefix.|Boolean| |Yes| | |
|12|SslClientKeyArn|The Amazon Resource Name (ARN) for the client private key used to securely connect to a Kafka target endpoint.|String| |No|Yes| |
|13|SslClientKeyPassword| The password for the client private key used to securely connect to a Kafka target endpoint.|String| |No|Yes| |
|14|SaslUserName| The secure user name you created when you first set up your Amazon MSK cluster to validate a client identity and make an encrypted connection between server and client using SASL-SSL authentication.  |String| |No| | |
|15|MessageMaxBytes|The maximum size in bytes for records created on the endpoint The default is 1,000,000.|Integer| |No| | |
|16|Topic|The topic to which you migrate the data. If you don't specify a topic, AWS DMS specifies "kafka-default-topic" as the migration topic.|String| |No| | |
|17|PartitionIncludeSchemaTable|Prefixes schema and table names to partition values, when the partition type is primary-key-type. Doing this increases data distribution among Kafka partitions. For example, suppose that a SysBench schema has thousands of tables and each table has only limited range for a primary key. In this case, the same primary key is sent from thousands of tables to the same partition, which causes throttling. The default is false.|Boolean| |Yes| | |
|18|IncludeNullAndEmpty|Include NULL and empty columns for records migrated to the endpoint. The default is false.|Boolean| |Yes| | |
||No.||Subprops of AWS_DMS_Endpoint KinesisSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|MessageFormat|The output format for the records created on the endpoint. The message format is JSON (default) or JSON_UNFORMATTED (a single line with no tab).|String| |Yes| | |
|2|IncludeTransactionDetails|Provides detailed transaction information from the source database. This information includes a commit timestamp, a log position, and values for transaction_id, previous transaction_id, and transaction_record_id (the record offset within a transaction). The default is false.|Boolean| |Yes| | |
|3|IncludeTableAlterOperations|Includes any data definition language (DDL) operations that change the table in the control data, such as rename-table, drop-table, add-column, drop-column, and rename-column. The default is false.|Boolean| |Yes| | |
|4|IncludeControlDetails|Shows detailed control information for table definition, column definition, and table and column changes in the Kinesis message output. The default is false.|Boolean| |Yes| | |
|5|IncludePartitionValue|Shows the partition value within the Kinesis message output, unless the partition type is schema-table-type. The default is false.|Boolean| |Yes| | |
|6|StreamArn|The Amazon Resource Name (ARN) for the Amazon Kinesis Data Streams endpoint.|String| |No|Yes| |
|7|ServiceAccessRoleArn|The Amazon Resource Name (ARN) for the IAM role that AWS DMS uses to write to the Kinesis data stream. The role must allow the iam:PassRole action.|String| |Yes|Yes| |
|8|NoHexPrefix|Set this optional parameter to true to avoid adding a '0x' prefix to raw data in hexadecimal format. For example, by default, AWS DMS adds a '0x' prefix to the LOB column type in hexadecimal format moving from an Oracle source to an Amazon Kinesis target. Use the NoHexPrefix endpoint setting to enable migration of RAW data type columns without adding the '0x' prefix.|Boolean| |Yes| | |
|9|PartitionIncludeSchemaTable|Prefixes schema and table names to partition values, when the partition type is primary-key-type. Doing this increases data distribution among Kinesis shards. For example, suppose that a SysBench schema has thousands of tables and each table has only limited range for a primary key. In this case, the same primary key is sent from thousands of tables to the same shard, which causes throttling. The default is false.|Boolean| |Yes| | |
|10|IncludeNullAndEmpty|Include NULL and empty columns for records migrated to the endpoint. The default is false.|Boolean| |Yes| | |
||No.||Subprops of AWS_DMS_Endpoint MicrosoftSqlServerSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|ReadBackupOnly|When this attribute is set to Y, AWS DMS only reads changes from transaction log backups and doesn't read from the active transaction log file during ongoing replication. Setting this parameter to Y enables you to control active transaction log file growth during full load and ongoing replication tasks. However, it can add some source latency to ongoing replication.|Boolean| |No| | |
|2|TlogAccessMode|Indicates the mode used to fetch CDC data.|String| |No| | |
|3|BcpPacketSize|The maximum size of the packets (in bytes) used to transfer data using BCP.|Integer| |No| | |
|4|Port|Endpoint TCP port.|Integer| |Yes| | |
|5|SafeguardPolicy|Use this attribute to minimize the need to access the backup log and enable AWS DMS to prevent truncation using one of the following two methods.|String| |No| | |
|6|UseThirdPartyBackupDevice|When this attribute is set to Y, DMS processes third-party  transaction log backups if they are created in native format.|Boolean| |No| | |
|7|DatabaseName|Database name for the endpoint.|String| |Yes| | |
|8|UseBcpFullLoad|Use this to attribute to transfer data for full-load operations using BCP. When the target table contains an identity column that does not exist in the source table, you must disable the use BCP for loading table option.|Boolean| |No| | |
|9|Username|Endpoint connection user name.|String| |Yes| | |
|10|QuerySingleAlwaysOnNode|Cleans and recreates table metadata information on the replication instance when  a mismatch occurs. An example is a situation where running an alter DDL statement on  a table might result in different information about the table cached in the replication  instance.|Boolean| |No| | |
|11|ServerName|Fully qualified domain name of the endpoint. For an Amazon RDS SQL Server instance, this is the output of DescribeDBInstances, in the Endpoint.Address field.|String| |Yes| | |
|12|SecretsManagerSecretId|The full ARN, partial ARN, or display name of the SecretsManagerSecret that contains the MicrosoftSQLServer endpoint connection details.|String| |Yes|Yes| |
|13|ControlTablesFileGroup|Specifies a file group for the AWS DMS internal tables. When the replication task starts, all the internal AWS DMS control tables (awsdms_ apply_exception, awsdms_apply, awsdms_changes) are created for the specified file group.|String| |No| | |
|14|ForceLobLookup|Forces LOB lookup on inline LOB.|Boolean| |No| | |
|15|SecretsManagerAccessRoleArn|The full Amazon Resource Name (ARN) of the IAM role that specifies AWS DMS as the trusted entity and grants the required permissions to access the value in SecretsManagerSecret. The role must allow the iam:PassRole action. SecretsManagerSecret has the value of the AWS Secrets Manager secret that allows access to the SQL Server endpoint.|String| |Yes|Yes| |
|16|TrimSpaceInChar|Use the TrimSpaceInChar source endpoint setting to right-trim data  on CHAR and NCHAR data types during migration. Setting TrimSpaceInChar does not left-trim data. The default value is true.|Boolean| |No| | |
|17|Password|Endpoint connection password.|String| |Yes|Yes| |
||No.||Subprops of AWS_DMS_Endpoint MongoDbSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|Port|The port value for the MongoDB source endpoint.|Integer| |Yes| | |
|2|ExtractDocId|Specifies the document ID. Use this setting when NestingLevel is set to "none".|String| |Yes|Yes| |
|3|DatabaseName|The database name on the MongoDB source endpoint.|String| |Yes| | |
|4|AuthSource|The MongoDB database name. This setting isn't used when AuthType is set to "no". |String| |No| | |
|5|AuthMechanism|The authentication mechanism you use to access the MongoDB source endpoint.|String| |No| | |
|6|Username|The user name you use to access the MongoDB source endpoint.|String| |Yes| | |
|7|DocsToInvestigate|Indicates the number of documents to preview to determine the document organization. Use this setting when NestingLevel is set to "one".|String| |Yes| | |
|8|ServerName|The name of the server on the MongoDB source endpoint.|String| |Yes| | |
|9|SecretsManagerSecretId|The full ARN, partial ARN, or display name of the SecretsManagerSecret that contains the MongoDB endpoint connection details.|String| |Yes|Yes| |
|10|AuthType|The authentication type you use to access the MongoDB source endpoint.|String| |Yes| | |
|11|SecretsManagerAccessRoleArn|The full Amazon Resource Name (ARN) of the IAM role that specifies AWS DMS as the trusted entity and grants the required permissions to access the value in SecretsManagerSecret. The role must allow the iam:PassRole action. SecretsManagerSecret has the value of the AWS Secrets Manager secret that allows access to the MongoDB endpoint.|String| |Yes|Yes| |
|12|Password|The password for the user account you use to access the MongoDB source endpoint.|String| |Yes|Yes| |
|13|NestingLevel|Specifies either document or table mode.|String| |Yes| | |
||No.||Subprops of AWS_DMS_Endpoint MySqlSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|ServerTimezone|Specifies the time zone for the source MySQL database.|String| |Yes| | |
|2|EventsPollInterval|Specifies how often to check the binary log for new changes/events when the database is idle. The default is five seconds.|Integer| |Yes| | |
|3|ParallelLoadThreads|Improves performance when loading data into the MySQL-compatible target database. Specifies how many threads to use to load the data into the MySQL-compatible target database. Setting a large number of threads can have an adverse effect on database performance, because a separate connection is required for each thread. The default is one.|Integer| |Yes| | |
|4|AfterConnectScript|Specifies a script to run immediately after AWS DMS connects to the endpoint. The migration task continues running regardless if the SQL statement succeeds or fails.|String| |Yes| | |
|5|MaxFileSize|Specifies the maximum size (in KB) of any .csv file used to transfer data to a MySQL-compatible database.|Integer| |Yes| | |
|6|TargetDbType|Specifies where to migrate source tables on the target, either to a single database or multiple databases. If you specify SPECIFIC_DATABASE, specify the database name using the DatabaseName parameter of the Endpoint object.|String| |No| | |
|7|SecretsManagerSecretId|The full ARN, partial ARN, or display name of the SecretsManagerSecret that contains the MySQL endpoint connection details.|String| |Yes|Yes| |
|8|SecretsManagerAccessRoleArn|The full Amazon Resource Name (ARN) of the IAM role that specifies AWS DMS as the trusted entity and grants the required permissions to access the value in SecretsManagerSecret. The role must allow the iam:PassRole action. SecretsManagerSecret has the value of the AWS Secrets Manager secret that allows access to the MySQL endpoint.|String| |Yes|Yes| |
|9|CleanSourceMetadataOnMismatch|Cleans and recreates table metadata information on the replication instance  when a mismatch occurs. For example, in a situation where running an alter DDL  on the table could result in different information about the table cached in the  replication instance. |Boolean| |Yes| | |
||No.||Subprops of AWS_DMS_Endpoint NeptuneSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|MaxRetryCount|The number of times for AWS DMS to retry a bulk load of migrated graph data to the Neptune target database before raising an error. The default is 5.|Integer| |No| | |
|2|MaxFileSize|The maximum size in kilobytes of migrated graph data stored in a .csv file before AWS DMS bulk-loads the data to the Neptune target database. The default is 1,048,576 KB. If the bulk load is successful, AWS DMS clears the bucket, ready to store the next batch of migrated graph data.|Integer| |Yes| | |
|3|S3BucketFolder|A folder path where you want AWS DMS to store migrated graph data in the S3 bucket specified by S3BucketName|String| |No| | |
|4|ErrorRetryDuration|The number of milliseconds for AWS DMS to wait to retry a bulk-load of migrated graph data to the Neptune target database before raising an error. The default is 250.|Integer| |Yes| | |
|5|IamAuthEnabled|If you want IAM authorization enabled for this endpoint, set this parameter to true. Then attach the appropriate IAM policy document to your service role specified by ServiceAccessRoleArn. The default is false.|Boolean| |No| | |
|6|S3BucketName|The name of the Amazon S3 bucket where AWS DMS can temporarily store migrated graph data in .csv files before bulk-loading it to the Neptune target database. AWS DMS maps the SQL source data to graph data before storing it in these .csv files.|String| |No| | |
|7|ServiceAccessRoleArn|The Amazon Resource Name (ARN) of the service role that you created for the Neptune target endpoint. The role must allow the iam:PassRole action.|String| |Yes|Yes| |
||No.||Subprops of AWS_DMS_Endpoint OracleSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|AsmPassword|For an Oracle source endpoint, your Oracle Automatic Storage Management (ASM) password. You can set this value from the asm_user_password value. You set this value as part of the comma-separated value that you set to the Password request parameter when you create the endpoint to access transaction logs using Binary Reader. For more information, see Configuration for change data capture (CDC) on an Oracle source database.|String| |No|Yes| |
|2|DirectPathParallelLoad|When set to true, this attribute specifies a parallel load when useDirectPathFullLoad is set to Y. This attribute also only applies when you use the AWS DMS parallel load feature. Note that the target table cannot have any constraints or indexes.|Boolean| |No| | |
|3|AdditionalArchivedLogDestId|Set this attribute with ArchivedLogDestId in a primary/ standby setup. This attribute is useful in the case of a switchover. In this case, AWS DMS needs to know which destination to get archive redo logs from to read changes. This need arises because the previous primary instance is now a standby instance after switchover.|Integer| |No|Yes| |
|4|SpatialDataOptionToGeoJsonFunctionName|Use this attribute to convert SDO_GEOMETRY to  GEOJSON format. By default, DMS calls the  SDO2GEOJSON custom function if present and accessible.  Or you can create your own custom function that mimics the operation of  SDOGEOJSON and set  SpatialDataOptionToGeoJsonFunctionName to call it instead. |String| |No| | |
|5|ReplacePathPrefix|Set this attribute to true in order to use the Binary Reader to capture change data for an Amazon RDS for Oracle as the source. This setting tells DMS instance to replace the default Oracle root with the specified usePathPrefix setting to access the redo logs.|Boolean| |No| | |
|6|FailTasksOnLobTruncation|When set to true, this attribute causes a task to fail if the actual size of an LOB column is greater than the specified LobMaxSize.|Boolean| |Yes| | |
|7|AsmServer|For an Oracle source endpoint, your ASM server address. You can set this value from the asm_server value. You set asm_server as part of the extra connection attribute string to access an Oracle server with Binary Reader that uses ASM. For more information, see Configuration for change data capture (CDC) on an Oracle source database.|String| |Yes| | |
|8|SecretsManagerOracleAsmAccessRoleArn|Required only if your Oracle endpoint uses Advanced Storage Manager (ASM). The full ARN of the IAM role that specifies AWS DMS as the trusted entity and grants the required permissions to access the SecretsManagerOracleAsmSecret. This SecretsManagerOracleAsmSecret has the secret value that allows access to the Oracle ASM of the endpoint.|String| |Yes|Yes| |
|9|OraclePathPrefix|Set this string attribute to the required value in order to use the Binary Reader to capture change data for an Amazon RDS for Oracle as the source. This value specifies the default Oracle root used to access the redo logs.|String| |No| | |
|10|ReadAheadBlocks|Set this attribute to change the number of read-ahead blocks that DMS configures to perform a change data capture (CDC) load using Oracle Automatic Storage Management (ASM). You can specify an integer value between 1000 (the default) and 200,000 (the maximum).|Integer| |No| | |
|11|StandbyDelayTime|Use this attribute to specify a time in minutes for the delay in standby sync. If the source is an Oracle Active Data Guard standby database, use this attribute to specify the time lag between primary and standby databases.|Integer| |No| | |
|12|AllowSelectNestedTables|Set this attribute to true to enable replication of Oracle tables containing columns that are nested tables or defined types.|Boolean| |No| | |
|13|AddSupplementalLogging|Set this attribute to set up table-level supplemental logging for the Oracle database. This attribute enables PRIMARY KEY supplemental logging on all tables selected for a migration task.|Boolean| |No| | |
|14|SecretsManagerSecretId|The full ARN, partial ARN, or display name of the SecretsManagerSecret that contains the Oracle endpoint connection details.|String| |Yes|Yes| |
|15|UseBFile|Set this attribute to True to capture change data using the Binary Reader utility. Set UseLogminerReader to False to set this attribute to True. To use Binary Reader with Amazon RDS for Oracle as the source, you set additional attributes. For more information about using this setting with Oracle Automatic Storage Management (ASM), see Using Oracle LogMiner or AWS DMS Binary Reader for CDC.|Boolean| |No| | |
|16|EnableHomogenousTablespace|Set this attribute to enable homogenous tablespace replication and create existing tables or indexes under the same tablespace on the target.|Boolean| |No| | |
|17|AsmUser|For an Oracle source endpoint, your ASM user name. You can set this value from the asm_user value. You set asm_user as part of the extra connection attribute string to access an Oracle server with Binary Reader that uses ASM. For more information, see Configuration for change data capture (CDC) on an Oracle source database.|String| |No| | |
|18|UseDirectPathFullLoad|Set this attribute to True to have AWS DMS use a direct path full load.  Specify this value to use the direct path protocol in the Oracle Call Interface (OCI).  By using this OCI protocol, you can bulk-load Oracle target tables during a full load.|Boolean| |No| | |
|19|SecurityDbEncryption|For an Oracle source endpoint, the transparent data encryption (TDE) password required by AWM DMS to access Oracle redo logs encrypted by TDE using Binary Reader. It is also the TDE_Password part of the comma-separated value you set to the Password request parameter when you create the endpoint. The SecurityDbEncryptian setting is related to this SecurityDbEncryptionName setting. For more information, see Supported encryption methods for using Oracle as a source for AWS DMS in the  AWS Database Migration Service User Guide. |String| |No|Yes| |
|20|ParallelAsmReadThreads|Set this attribute to change the number of threads that DMS configures to perform a change data capture (CDC) load using Oracle Automatic Storage Management (ASM). You can specify an integer value between 2 (the default) and 8 (the maximum). Use this attribute together with the readAheadBlocks attribute.|Integer| |No| | |
|21|ArchivedLogDestId|Specifies the ID of the destination for the archived redo logs. This value should be the same as a number in the dest_id column of the v$archived_log view. If you work with an additional redo log destination, use the AdditionalArchivedLogDestId option to specify the additional destination ID. Doing this improves performance by ensuring that the correct logs are accessed from the outset.|Integer| |No|Yes| |
|22|UsePathPrefix|Set this string attribute to the required value in order to use the Binary Reader to capture change data for an Amazon RDS for Oracle as the source. This value specifies the path prefix used to replace the default Oracle root to access the redo logs.|String| |No| | |
|23|UseLogminerReader|Set this attribute to True to capture change data using the Oracle LogMiner utility (the default). Set this attribute to False if you want to access the redo logs as a binary file. When you set UseLogminerReader to False, also set UseBfile to True. For more information on this setting and using Oracle ASM, see Using Oracle LogMiner or AWS DMS Binary Reader for CDC in the  AWS DMS User Guide.|Boolean| |No| | |
|24|SecurityDbEncryptionName|For an Oracle source endpoint, the name of a key used for the transparent data encryption (TDE) of the columns and tablespaces in an Oracle source database that is encrypted using TDE. The key value is the value of the SecurityDbEncryption setting. For more information on setting the key name value of SecurityDbEncryptionName, see the information and example for setting the securityDbEncryptionName extra connection attribute in Supported encryption methods for using Oracle as a source for AWS DMS in the  AWS Database Migration Service User Guide.|String| |No|Yes| |
|25|DirectPathNoLog|When set to true, this attribute helps to increase the commit rate on the Oracle target database by writing directly to tables and not writing a trail to database logs.|Boolean| |No| | |
|26|SecretsManagerOracleAsmSecretId|Required only if your Oracle endpoint uses Advanced Storage Manager (ASM). The full ARN, partial ARN, or display name of the SecretsManagerOracleAsmSecret that contains the Oracle ASM connection details for the Oracle endpoint.|String| |Yes|Yes| |
|27|CharLengthSemantics|Specifies whether the length of a character column is in bytes or in characters. To indicate that the character column length is in characters, set this attribute to CHAR. Otherwise, the character column length is in bytes.|String| |No| | |
|28|NumberDatatypeScale|Specifies the number scale. You can select a scale up to 38, or you can select FLOAT. By default, the NUMBER data type is converted to precision 38, scale 10.|Integer| |No| | |
|29|ReadTableSpaceName|When set to true, this attribute supports tablespace replication.|Boolean| |No| | |
|30|AccessAlternateDirectly|Set this attribute to false in order to use the Binary Reader to capture change data for an Amazon RDS for Oracle as the source. This tells the DMS instance to not access redo logs through any specified path prefix replacement using direct file access.|Boolean| |No| | |
|31|UseAlternateFolderForOnline|Set this attribute to true in order to use the Binary Reader to capture change data for an Amazon RDS for Oracle as the source. This tells the DMS instance to use any specified prefix replacement to access all online redo logs.|Boolean| |No| | |
|32|ArchivedLogsOnly|When this field is set to True, AWS DMS only accesses the archived redo logs. If the archived redo logs are stored on Automatic Storage Management (ASM) only, the AWS DMS user account needs to be granted ASM privileges.|Boolean| |No| | |
|33|ExtraArchivedLogDestIds|Specifies the IDs of one more destinations for one or more archived redo logs. These IDs are the values of the dest_id column in the v$archived_log view. Use this setting with the archivedLogDestId extra connection attribute in a primary-to-single setup or a primary-to-multiple-standby setup. |Array of Integer| |No|Yes| |
|34|RetryInterval|Specifies the number of seconds that the system waits before resending a query.|Integer| |No| | |
|35|SecretsManagerAccessRoleArn|The full Amazon Resource Name (ARN) of the IAM role that specifies AWS DMS as the trusted entity and grants the required permissions to access the value in SecretsManagerSecret. The role must allow the iam:PassRole action. SecretsManagerSecret has the value of the AWS Secrets Manager secret that allows access to the Oracle endpoint.|String| |Yes|Yes| |
||No.||Subprops of AWS_DMS_Endpoint PostgreSqlSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|PluginName|Specifies the plugin to use to create a replication slot.|String| |No| | |
|2|MapBooleanAsBoolean|When true, lets PostgreSQL migrate the boolean type as boolean. By default, PostgreSQL migrates booleans as  varchar(5). You must set this setting on both the source and target endpoints for it to take effect.|Boolean| |Yes| | |
|3|AfterConnectScript|For use with change data capture (CDC) only, this attribute has AWS DMS bypass foreign keys and user triggers to reduce the time it takes to bulk load data.|String| |Yes| | |
|4|ExecuteTimeout|Sets the client statement timeout for the PostgreSQL instance, in seconds. The default value is 60 seconds.|Integer| |No| | |
|5|DdlArtifactsSchema|The schema in which the operational DDL database artifacts are created.|String| |No| | |
|6|FailTasksOnLobTruncation|When set to true, this value causes a task to fail if the actual size of a LOB column is greater than the specified LobMaxSize.|Boolean| |Yes| | |
|7|HeartbeatEnable|The write-ahead log (WAL) heartbeat feature mimics a dummy transaction. By doing this, it prevents idle logical replication slots from holding onto old WAL logs, which can result in storage full situations on the source. This heartbeat keeps restart_lsn moving and prevents storage full scenarios.|Boolean| |No| | |
|8|BabelfishDatabaseName|The Babelfish for Aurora PostgreSQL database name for the endpoint.|String| |No| | |
|9|DatabaseMode|Specifies the default behavior of the replication's handling of PostgreSQL- compatible endpoints that require some additional configuration, such as Babelfish endpoints.|String| |No| | |
|10|CaptureDdls|To capture DDL events, AWS DMS creates various artifacts in the PostgreSQL database when the task starts. You can later remove these artifacts.|Boolean| |No| | |
|11|MaxFileSize|Specifies the maximum size (in KB) of any .csv file used to transfer data to PostgreSQL.|Integer| |Yes| | |
|12|HeartbeatFrequency|Sets the WAL heartbeat frequency (in minutes).|Integer| |No| | |
|13|SecretsManagerSecretId|The full ARN, partial ARN, or display name of the SecretsManagerSecret that contains the PostgreSQL endpoint connection details.|String| |Yes|Yes| |
|14|SecretsManagerAccessRoleArn|The full Amazon Resource Name (ARN) of the IAM role that specifies AWS DMS as the trusted entity and grants the required permissions to access the value in SecretsManagerSecret. The role must allow the iam:PassRole action. SecretsManagerSecret has the value of the AWS Secrets Manager secret that allows access to the PostgreSQL endpoint.|String| |Yes|Yes| |
|15|HeartbeatSchema|Sets the schema in which the heartbeat artifacts are created.|String| |No| | |
|16|SlotName|Sets the name of a previously created logical replication slot for a change data capture (CDC) load of the PostgreSQL source instance. |String| |No| | |
||No.||Subprops of AWS_DMS_Endpoint RedisSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|SslSecurityProtocol|The connection to a Redis target endpoint using Transport Layer Security (TLS). Valid values include plaintext and ssl-encryption. The default is ssl-encryption. The ssl-encryption option makes an encrypted connection. Optionally, you can identify an Amazon Resource Name (ARN) for an SSL certificate authority (CA)  using the SslCaCertificateArn setting. If an ARN isn't given for a CA, DMS uses the Amazon root CA.|String| |No| | |
|2|AuthUserName|The user name provided with the auth-role option of the  AuthType setting for a Redis target endpoint.|String| |No| | |
|3|ServerName|Fully qualified domain name of the endpoint.|String| |Yes| | |
|4|Port|Transmission Control Protocol (TCP) port for the endpoint.|Number| |Yes| | |
|5|SslCaCertificateArn|The Amazon Resource Name (ARN) for the certificate authority (CA) that DMS uses to connect to your Redis target endpoint.|String| |Yes|Yes| |
|6|AuthPassword|The password provided with the auth-role and  auth-token options of the AuthType setting for a Redis  target endpoint.|String| |No|Yes| |
|7|AuthType|The type of authentication to perform when connecting to a Redis target. Options include none, auth-token, and auth-role. The auth-token option requires an AuthPassword value to be provided. The auth-role option requires AuthUserName and AuthPassword values to be provided.|String| |Yes| | |
||No.||Subprops of AWS_DMS_Endpoint RedshiftSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|ConnectionTimeout|A value that sets the amount of time to wait (in milliseconds) before timing out, beginning from when you initially establish a connection.|Integer| |No| | |
|2|MapBooleanAsBoolean|When true, lets Redshift migrate the boolean type as boolean. By default, Redshift migrates booleans as  varchar(1). You must set this setting on both the source and target endpoints for it to take effect.|Boolean| |Yes| | |
|3|AfterConnectScript|Code to run after connecting. This parameter should contain the code itself, not the name of a file containing the code.|String| |Yes| | |
|4|FileTransferUploadStreams|The number of threads used to upload a single file. This parameter accepts a value from 1 through 64. It defaults to 10.|Integer| |No| | |
|5|BucketName|The name of the intermediate S3 bucket used to store .csv files before uploading data to Redshift.|String| |Yes| | |
|6|ServerSideEncryptionKmsKeyId|The AWS KMS key ID. If you are using SSE_KMS for the EncryptionMode, provide this key ID. The key that you use needs an attached policy that enables IAM user permissions and allows use of the key.|String| |Yes|Yes| |
|7|ExplicitIds|This setting is only valid for a full-load migration task. Set ExplicitIds to true to have tables with IDENTITY columns override their auto-generated values with explicit values loaded from the source data files used to populate the tables. The default is false.|Boolean| |No|Yes| |
|8|SecretsManagerSecretId|The full ARN, partial ARN, or display name of the SecretsManagerSecret that contains the Amazon Redshift endpoint connection details.|String| |Yes|Yes| |
|9|TruncateColumns|A value that specifies to truncate data in columns to the appropriate number of characters, so that the data fits in the column. This parameter applies only to columns with a VARCHAR or CHAR data type, and rows with a size of 4 MB or less. Choose true to truncate data. The default is false.|Boolean| |No| | |
|10|ServiceAccessRoleArn|The Amazon Resource Name (ARN) of the IAM role that has access to the Amazon Redshift service. The role must allow the iam:PassRole action.|String| |Yes|Yes| |
|11|ReplaceChars|A value that specifies to replaces the invalid characters specified in ReplaceInvalidChars, substituting the specified characters instead. The default is "?".|String| |No| | |
|12|TimeFormat|The time format that you want to use. Valid values are auto (case-sensitive), 'timeformat_string', 'epochsecs', or 'epochmillisecs'. It defaults to 10. Using auto recognizes most strings, even some that aren't supported when you use a time format string. |String| |No| | |
|13|BucketFolder|An S3 folder where the comma-separated-value (.csv) files are stored before being  uploaded to the target Redshift cluster. |String| |Yes| | |
|14|ReplaceInvalidChars|A list of characters that you want to replace. Use with ReplaceChars.|String| |No| | |
|15|RemoveQuotes|A value that specifies to remove surrounding quotation marks from strings in the incoming data. All characters within the quotation marks, including delimiters, are retained. Choose true to remove quotation marks. The default is false.|Boolean| |No| | |
|16|LoadTimeout|The amount of time to wait (in milliseconds) before timing out of operations performed  by AWS DMS on a Redshift cluster, such as Redshift COPY, INSERT, DELETE, and UPDATE.|Integer| |Yes| | |
|17|MaxFileSize|The maximum size (in KB) of any .csv file used to load data on an S3 bucket and transfer  data to Amazon Redshift. It defaults to 1048576KB (1 GB).|Integer| |Yes| | |
|18|TrimBlanks|A value that specifies to remove the trailing white space characters from a VARCHAR string. This parameter applies only to columns with a VARCHAR data type. Choose true to remove unneeded white space. The default is false.|Boolean| |No| | |
|19|DateFormat|The date format that you are using. Valid values are auto (case-sensitive), your date format string enclosed in quotes, or NULL. If this parameter is left unset (NULL), it defaults to a format of 'YYYY-MM-DD'. Using auto recognizes most strings, even some that aren't supported when you use a date format string. |String| |No| | |
|20|CompUpdate|If you set CompUpdate to true Amazon Redshift applies automatic compression if the table is empty. This applies even if the table columns already have encodings other than RAW. If you set CompUpdate to false, automatic compression is disabled and existing column encodings aren't changed. The default is true.|Boolean| |No| | |
|21|AcceptAnyDate|A value that indicates to allow any date format, including invalid formats such as 00/00/00 00:00:00, to be loaded without generating an error. You can choose true or false (the default).|Boolean| |No| | |
|22|WriteBufferSize|The size (in KB) of the in-memory file write buffer used when generating .csv files  on the local disk at the DMS replication instance. The default value is 1000  (buffer size is 1000KB).|Integer| |Yes| | |
|23|SecretsManagerAccessRoleArn|The full Amazon Resource Name (ARN) of the IAM role that specifies AWS DMS as the trusted entity and grants the required permissions to access the value in SecretsManagerSecret. The role must allow the iam:PassRole action. SecretsManagerSecret has the value of the AWS Secrets Manager secret  that allows access to the Amazon Redshift endpoint.|String| |Yes|Yes| |
|24|CaseSensitiveNames|If Amazon Redshift is configured to support case sensitive schema names, set CaseSensitiveNames to true. The default is false.|Boolean| |No| | |
|25|EmptyAsNull|A value that specifies whether AWS DMS should migrate empty CHAR and VARCHAR fields as NULL. A value of true sets empty CHAR and VARCHAR fields to null. The default is false.|Boolean| |No| | |
|26|EncryptionMode|The type of server-side encryption that you want to use for your data. This encryption type is part of the endpoint settings or the extra connections attributes for Amazon S3. You can choose either SSE_S3 (the default) or SSE_KMS. |String| |Yes|Yes| |
||No.||Subprops of AWS_DMS_Endpoint S3Settings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|TimestampColumnName|A value that when nonblank causes AWS DMS to add a column with timestamp information to the endpoint data for an Amazon S3 target.|String| |No| | |
|2|EnableStatistics|A value that enables statistics for Parquet pages and row groups. Choose true to enable statistics, false to disable. Statistics include NULL, DISTINCT, MAX, and MIN values. This parameter defaults to true. This value is used for .parquet file format only.|Boolean| |No| | |
|3|DatePartitionSequence|Identifies the sequence of the date format to use during folder partitioning. The default value is  YYYYMMDD. Use this parameter when DatePartitionedEnabled is set to true.|String| |No| | |
|4|CsvNullValue|An optional parameter that specifies how AWS DMS treats null values. While handling the null value, you can use this parameter to pass a user-defined string as null when writing to the target. For example, when target columns are not nullable, you can use this option to differentiate between the empty string value and the null value. So, if you set this parameter value to the empty string ("" or ''), AWS DMS treats the empty string as the null value instead of NULL.|String| |No| | |
|5|IncludeOpForFullLoad|A value that enables a full load to write INSERT operations to the comma-separated value (.csv) output files only to indicate how the rows were added to the source database.|Boolean| |No| | |
|6|CdcInsertsAndUpdates|A value that enables a change data capture (CDC) load to write INSERT and UPDATE operations to .csv or .parquet (columnar storage) output files. The default setting is false, but when CdcInsertsAndUpdates is set to true or y, only INSERTs and UPDATEs from the source database are migrated to the .csv or .parquet file. |Boolean| |No| | |
|7|BucketName|The name of the S3 bucket.|String| |Yes| | |
|8|ServerSideEncryptionKmsKeyId|If you are using SSE_KMS for the EncryptionMode, provide the AWS KMS key ID. The key that you use needs an attached policy that enables  IAM user permissions and allows use of the key.|String| |Yes|Yes| |
|9|UseTaskStartTimeForFullLoadTimestamp|When set to true, this parameter uses the task start time as the timestamp column value instead of  the time data is written to target. For full load, when useTaskStartTimeForFullLoadTimestamp is set to true, each row of the timestamp column contains the task start time. For CDC loads,  each row of the timestamp column contains the transaction commit time.|Boolean| |No| | |
|10|GlueCatalogGeneration|When true, allows AWS Glue to catalog your S3 bucket. Creating an AWS Glue catalog lets you use Athena to query your data.|Boolean| |No| | |
|11|DataFormat|The format of the data that you want to use for output. You can choose one of the following: |String| |No| | |
|12|CsvDelimiter|The delimiter used to separate columns in the .csv file for both source and target. The default is a comma.|String| |No| | |
|13|AddTrailingPaddingCharacter|Use the S3 target endpoint setting AddTrailingPaddingCharacter to add  padding on string data. The default value is false.|Boolean| |No| | |
|14|IgnoreHeaderRows|When this value is set to 1, AWS DMS ignores the first row header in a .csv file. A value of 1 turns on the feature; a value of 0 turns off the feature.|Integer| |No| | |
|15|CannedAclForObjects|A value that enables AWS DMS to specify a predefined (canned) access control list (ACL) for objects created in an Amazon S3 bucket as .csv or .parquet files. For more information about Amazon S3 canned ACLs, see  Canned ACL in the Amazon S3 Developer Guide.|String| |No| | |
|16|Rfc4180|For an S3 source, when this value is set to true or y, each leading double quotation mark has to be followed by an ending double quotation mark. This formatting complies with RFC 4180. When this value is set to false or n, string literals are copied to the target as is. In this case, a delimiter (row or column) signals the end of the field. Thus, you can't use a delimiter as part of the string, because it signals the end of the value.|Boolean| |No| | |
|17|ServiceAccessRoleArn|A required parameter that specifies the Amazon Resource Name (ARN) used by the service to access the IAM role. The role must allow the iam:PassRole action. It enables AWS DMS to read and write objects from an S3 bucket.|String| |Yes|Yes| |
|18|ParquetTimestampInMillisecond|A value that specifies the precision of any TIMESTAMP column values that are written to an Amazon S3 object file in .parquet format.|Boolean| |No| | |
|19|PreserveTransactions|If this setting is set to true, AWS DMS saves the transaction order for a change data capture (CDC) load on the Amazon S3 target specified by CdcPath. For more information, see  Capturing data changes (CDC) including transaction order on the S3 target.|Boolean| |No| | |
|20|BucketFolder|An optional parameter to set a folder name in the S3 bucket. If provided, tables are created in the path bucketFolder/schema_name/table_name/. If this parameter isn't specified, the path used is schema_name/table_name/.|String| |Yes| | |
|21|DatePartitionDelimiter|Specifies a date separating delimiter to use during folder partitioning. The default value is  SLASH. Use this parameter when DatePartitionedEnabled is set to true.|String| |No| | |
|22|EncodingType|The type of encoding that you're using: |String| |No| | |
|23|AddColumnName|An optional parameter that, when set to true or y, you can use to add column name information to the .csv output file.|Boolean| |No| | |
|24|CdcMinFileSize|Minimum file size, defined in kilobytes, to reach for a file output to Amazon S3.|Integer| |No| | |
|25|ParquetVersion|The version of the Apache Parquet format that you want to use: parquet_1_0 (the default) or parquet_2_0.|String| |No| | |
|26|ExternalTableDefinition|The external table definition.|String| |No| | |
|27|UseCsvNoSupValue|This setting applies if the S3 output files during a change data capture (CDC) load are written in .csv format. If this setting is set to true for columns not included in the supplemental log, AWS DMS uses the value specified by CsvNoSupValue. If this setting isn't set or is set to false, AWS DMS uses the null value for these columns.|Boolean| |No| | |
|28|MaxFileSize|A value that specifies the maximum size (in KB) of any .csv file to be created while migrating to an S3 target during full load.|Integer| |Yes| | |
|29|CdcPath|Specifies the folder path of CDC files. For an S3 source, this setting is required if a task captures change data; otherwise, it's optional. If CdcPath is set, AWS DMS reads CDC files from this path and replicates the data changes to the target endpoint. For an S3 target if you set PreserveTransactions to true, AWS DMS verifies that you have set this parameter to a folder path on your S3 target where AWS DMS can save the transaction order for the CDC load. AWS DMS creates this CDC folder path in either your S3 target working directory or the S3 target location specified by BucketFolder and BucketName.|String| |No| | |
|30|CsvNoSupValue|This setting only applies if your Amazon S3 output files during a change data capture (CDC) load are written in .csv format. If UseCsvNoSupValue is set to true, specify a string value that you want AWS DMS to use for all columns not included in the supplemental log. If you do not specify a string value, AWS DMS uses the null value for these columns regardless of the UseCsvNoSupValue setting.|String| |No| | |
|31|CdcMaxBatchInterval|Maximum length of the interval, defined in seconds, after which to output a file to Amazon S3.|Integer| |No| | |
|32|CsvRowDelimiter|The delimiter used to separate rows in the .csv file for both source and target.|String| |No| | |
|33|RowGroupLength|The number of rows in a row group. A smaller row group size provides faster reads. But as the number of row groups grows, the slower writes become. This parameter defaults to 10,000 rows. This number is used for .parquet file format only. |Integer| |No| | |
|34|DataPageSize|The size of one data page in bytes. This parameter defaults to 1024 * 1024 bytes (1 MiB). This number is used for .parquet file format only. |Integer| |No| | |
|35|DatePartitionEnabled|When set to true, this parameter partitions S3 bucket folders based on transaction commit dates. The default value is false. For more information about date-based folder partitioning, see  Using date-based folder partitioning.|Boolean| |No| | |
|36|DictPageSizeLimit|The maximum size of an encoded dictionary page of a column. If the dictionary page exceeds this, this column is stored using an encoding type of PLAIN. This parameter defaults to 1024 * 1024 bytes (1 MiB), the maximum size of a dictionary page before it reverts to PLAIN encoding. This size is used for .parquet file format only. |Integer| |No| | |
|37|CompressionType|An optional parameter. When set to GZIP it enables the service to compress the target files. To allow the service to write the target files uncompressed, either set this parameter to NONE (the default) or don't specify the parameter at all. This parameter applies to both .csv and .parquet file formats.|String| |No| | |
|38|DatePartitionTimezone|When creating an S3 target endpoint, set DatePartitionTimezone to convert the current UTC time into a specified time zone. The conversion occurs when a date partition folder is created and a change data capture (CDC) file name is generated. The time zone format is Area/Location. Use this parameter when DatePartitionedEnabled is set to true, as shown in the following example.|String| |No| | |
|39|CdcInsertsOnly|A value that enables a change data capture (CDC) load to write only INSERT operations to .csv or columnar storage (.parquet) output files. By default (the false setting), the first field in a .csv or .parquet record contains the letter I (INSERT), U (UPDATE), or D (DELETE). These values indicate whether the row was inserted, updated, or deleted at the source database for a CDC load to the target.|Boolean| |No| | |
|40|ExpectedBucketOwner|To specify a bucket owner and prevent sniping, you can use the  ExpectedBucketOwner endpoint setting. |String| |No| | |
|41|EncryptionMode|The type of server-side encryption that you want to use for your data. This encryption type is part of the endpoint settings or the extra connections attributes for Amazon S3. You can choose either SSE_S3 (the default) or SSE_KMS. |String| |Yes|Yes| |
||No.||Subprops of AWS_DMS_Endpoint SybaseSettings||Description||Type||Threat Context||Common Property||GR Required||Jira Story
|1|SecretsManagerSecretId|The full ARN, partial ARN, or display name of the SecretsManagerSecret that contains the SAP SAE endpoint connection details.|String| |Yes|Yes| |
|2|SecretsManagerAccessRoleArn|The full Amazon Resource Name (ARN) of the IAM role that specifies AWS DMS as the trusted entity and grants the required permissions to access the value in SecretsManagerSecret. The role must allow the iam:PassRole action. SecretsManagerSecret has the value of the AWS Secrets Manager secret that allows access to the SAP ASE endpoint.|String| |Yes|Yes| |
